{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from snorkel.learning import GenerativeModel\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.optimize import minimize\n",
    "from snorkel.learning.structure import DependencySelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Primitives\n",
    "def has_bike(object_names):\n",
    "    if ('cycle' in object_names) or ('bike' in object_names) or ('bicycle' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def has_human(object_names):\n",
    "    if (('person' in object_names) or ('woman' in object_names) or ('man' in object_names)) \\\n",
    "        and (('bicycle' in object_names) or 'bicycles' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def has_road(object_names):\n",
    "    if ('road' in object_names) or ('street' in object_names) or ('concrete' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def has_cars(object_names):\n",
    "    if ('car' in object_names) or ('cars' in object_names) or \\\n",
    "        ('bus' in object_names) or ('buses' in object_names) or \\\n",
    "        ('truck' in object_names) or ('trucks' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n"
     ]
    }
   ],
   "source": [
    "from primitive_helpers import bike_human_distance, bike_human_size, bike_human_nums\n",
    "from data_loader import DataLoader\n",
    "loader = DataLoader()\n",
    "\n",
    "def create_primitives(loader):\n",
    "    m = 7 # number of primitives\n",
    "    primitive_mtx = np.zeros((loader.train_num,m))\n",
    "\n",
    "    for i in range(loader.train_num):\n",
    "        primitive_mtx[i,0] = has_human(loader.train_object_names[i])\n",
    "        primitive_mtx[i,1] = has_road(loader.train_object_names[i])\n",
    "        primitive_mtx[i,2] = has_cars(loader.train_object_names[i])\n",
    "        primitive_mtx[i,3] = has_bike(loader.train_object_names[i])\n",
    "\n",
    "        primitive_mtx[i,4] = bike_human_distance(loader.train_object_names[i], \n",
    "                                                 loader.train_object_x[i], \n",
    "                                                 loader.train_object_y[i])\n",
    "\n",
    "        area = np.multiply(loader.train_object_height[i], loader.train_object_width[i])\n",
    "        primitive_mtx[i,5] = bike_human_size(loader.train_object_names[i], area)\n",
    "        primitive_mtx[i,6] = bike_human_nums(loader.train_object_names[i])\n",
    "\n",
    "    return primitive_mtx\n",
    "primitive_mtx = create_primitives(loader)\n",
    "\n",
    "p_keys = {\n",
    "    'has_human': primitive_mtx[:,0],\n",
    "    'has_road': primitive_mtx[:, 1],\n",
    "    'has_cars': primitive_mtx[:, 2],\n",
    "    'has_bike': primitive_mtx[:, 3],\n",
    "    'bike_human_distance': primitive_mtx[:, 4],\n",
    "    'bike_human_size': primitive_mtx[:, 5],\n",
    "    'bike_human_num': primitive_mtx[:, 6]\n",
    "   }\n",
    "pos = list(np.where(loader.train_ground>0)[0])\n",
    "neg = list(np.where(loader.train_ground<0)[0])[-len(pos):]\n",
    "chosen_data = pos + neg\n",
    "print(len(chosen_data))\n",
    "loader.train_ground = loader.train_ground[chosen_data]\n",
    "loader.train_num = len(chosen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract X and Y \n",
    "X = np.zeros((len(chosen_data), 512))\n",
    "from img_to_vec import Img2Vec\n",
    "import skimage.io as io\n",
    "from PIL import Image\n",
    "img2vec = Img2Vec()\n",
    "print()\n",
    "for i in range(len(chosen_data)):\n",
    "    j = chosen_data[i]\n",
    "    img = io.imread(loader.data[int(loader.train_vg_idx[j])]['url'])\n",
    "    img = Image.fromarray(img)\n",
    "    X[i,] = img2vec.get_vec(img)\n",
    "Y = loader.train_ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 512) (540,)\n",
      "(0.62962962962962965, 0.61538461538461531) [678, 813, 662, 172, 607, 70, 47, 789, 208, 757, 824, 867, 769, 295, 614, 554, 66, 891, 547, 825, 9, 369, 134, 760, 571, 45, 143, 697, 5, 724, 738, 201, 875, 339, 636, 551, 82, 887, 783, 74, 19, 605, 848, 335, 110, 519, 869, 371, 356, 546, 675, 574, 745, 735, 460, 650, 716, 732, 781, 535, 707, 879, 441, 711, 212, 561, 756, 550, 630, 872, 727, 728, 648, 253, 336, 591, 466, 290, 503, 868, 754, 775, 696, 258, 322, 543, 538, 660, 603, 229, 620, 857, 873, 373, 579, 628, 694, 768, 736, 527, 655, 740, 569, 109, 431, 840, 870, 195, 349, 552, 637, 871, 703, 488, 894, 733, 113, 627, 659, 541, 471, 753, 473, 778, 829, 392, 714, 303, 456, 786, 568, 305, 762, 558, 689, 384, 612, 674, 811, 616, 835, 797, 606, 764, 581, 397, 610, 739, 796, 734, 408, 856, 595, 847, 729, 843, 695, 597, 559, 712, 670, 613, 351, 596, 619, 669, 656, 584, 492, 702, 763, 839, 743, 542, 588, 425, 654, 862, 761, 359, 378, 685, 741, 771, 884, 405, 888, 544, 819, 866, 330, 900, 645, 418, 706, 132, 860, 206, 540, 268, 803, 625, 742, 525, 35, 107, 78, 555, 454, 767, 672, 737, 297, 154, 792, 723, 634, 802, 594, 751, 118, 823, 747, 686, 539, 641, 845, 788, 8, 850, 842, 311, 748, 809, 710, 800, 557, 306, 556, 717, 202, 140, 102, 895, 601, 664, 837, 77, 810, 759, 864, 673, 548, 537, 693, 807, 430, 203, 424, 406, 880, 21, 600, 623, 205, 566, 41, 518, 117, 676, 858, 782, 718, 720, 532, 822, 817, 615, 779, 687, 709, 560, 854, 834, 889, 855, 570, 632, 902, 851, 667, 536, 128, 719, 705, 642, 578, 863, 327, 161, 690, 2, 831, 643, 148, 731, 252, 680, 106, 750, 877, 746, 787, 770, 657, 287, 618, 876, 156, 624, 886, 793, 36, 586, 281, 688, 526, 545, 602, 893, 421, 575, 827, 882, 590, 804, 164, 652, 150, 853, 573, 772, 633, 899, 798, 629, 815, 553, 861, 179, 814, 838, 63, 583, 794, 534, 529, 644, 684, 725, 836, 622, 577, 412, 307, 666, 279, 791, 604, 715, 801, 380, 62, 222, 329, 522, 755, 318]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/snorkel/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test, chosen_train, chosen_test = train_test_split(X, Y, chosen_data, test_size=0.3, random_state=42)\n",
    "def metric(labels):\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, labels)\n",
    "    labels = clf.predict(X_test)\n",
    "    gen = np.mean(labels == Y_test)\n",
    "    f1_gen = f1_score(Y_test, labels)\n",
    "    return gen, f1_gen \n",
    "print(metric(Y_train), chosen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1 = []\n",
    "#x2 = []\n",
    "def LF_street(has_human, has_road):\n",
    "    if has_human >= 1: \n",
    "        if has_road >= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    return -1\n",
    "\n",
    "def LF_vehicles(has_human, has_cars):\n",
    "    if has_human >= 1: \n",
    "        if has_cars >= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    return -1\n",
    "\n",
    "# def LF_vehicles(has_human, has_bikes):\n",
    "#     if has_human >= 1: \n",
    "#         if has_bikes >= 1:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return -1\n",
    "#     return -1\n",
    "\n",
    "def LF_has_cars(has_cars):\n",
    "    if has_cars >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1 \n",
    "def LF_has_road(has_road):\n",
    "    if has_road >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1 \n",
    "\n",
    "def LF_distance(has_human, has_bike, bike_human_distance, thre=8):\n",
    "    if has_human >= 1:\n",
    "        if has_bike >= 1: \n",
    "            #x1.append(bike_human_distance)\n",
    "            if bike_human_distance <= thre:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            return 0 \n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "def LF_size(has_human, has_bike, bike_human_size, thre=1000):\n",
    "    if has_human >= 1:\n",
    "        if has_bike >= 1: \n",
    "            #x2.append(bike_human_size)\n",
    "            if bike_human_size <= thre:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "def LF_number(has_human, has_bike, bike_human_num):\n",
    "    if has_human >= 1:\n",
    "        if has_bike >= 1: \n",
    "            if bike_human_num >= 2:\n",
    "                return 1\n",
    "            if bike_human_num >= 1:\n",
    "                return 0\n",
    "            if bike_human_num >= 0:\n",
    "                return 1 \n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f(alpha, L_fns=None, ind=None, weights=None, epochs=None):\n",
    "#     \"\"\"L_fns: list of functions\n",
    "#        l: list of indicator for whether thresholds involve in the particular function \n",
    "#     \"\"\"\n",
    "#     #alpha = np.exp(alpha)\n",
    "#     for i in range(len(ind)):\n",
    "#         L_fns[ind[i]] = partial(L_fns[ind[i]], thre=alpha[i])\n",
    "        \n",
    "#     L = np.zeros((len(L_fns),loader.train_num)).astype(int)\n",
    "    \n",
    "#     for j in range(len(chosen_data)):\n",
    "#         i = chosen_data[j]\n",
    "#         L[0,j] = L_fns[0](p_keys['has_human'][i], p_keys['has_road'][i])\n",
    "#         L[1,j] = L_fns[1](p_keys['has_human'][i], p_keys['has_cars'][i])\n",
    "#         L[2,j] = L_fns[2](p_keys['has_human'][i], p_keys['has_bike'][i], p_keys['bike_human_distance'][i])\n",
    "#         L[3,j] = L_fns[3](p_keys['has_human'][i], p_keys['has_bike'][i], p_keys['bike_human_size'][i])\n",
    "#         L[4,j] = L_fns[4](p_keys['has_human'][i], p_keys['has_bike'][i], p_keys['bike_human_num'][i])\n",
    "        \n",
    "#     L_train = sparse.csr_matrix(L.T)\n",
    "#     gen_model = GenerativeModel()\n",
    "#     gen_model.train(L.T, epochs=epochs, decay=0.95, step_size= 0.01/ L.shape[1], reg_param=1e-6)\n",
    "#     if weights is not None:\n",
    "#         gen_model.weights = weights\n",
    "#     train_marginals, likelihood = gen_model.marginals(L_train)\n",
    "#     labels = 2 * (train_marginals > 0.5) - 1\n",
    "#     gen = np.mean(labels == loader.train_ground)\n",
    "#     f1_gen = f1_score(loader.train_ground, labels)\n",
    "#     if weights is None:\n",
    "#         return (gen,f1_gen), gen_model.weights, -likelihood \n",
    "#     else:\n",
    "#         return -likelihood \n",
    "\n",
    "    \n",
    "def f(alpha, L_fns=None, ind=None, weights=None, epochs=None):\n",
    "    \"\"\"L_fns: list of functions\n",
    "       l: list of indicator for whether thresholds involve in the particular function \n",
    "    \"\"\"\n",
    "    #alpha = np.exp(alpha)\n",
    "    for i in range(len(ind)):\n",
    "        L_fns[ind[i]] = partial(L_fns[ind[i]], thre=alpha[i])\n",
    "        \n",
    "    L = np.zeros((len(L_fns),len(X_train))).astype(int)\n",
    "    \n",
    "    for j in range(len(chosen_train)):\n",
    "        i = chosen_train[j]\n",
    "#         for i in range(len(L_fns)):\n",
    "#             L[i,j] = L_fns[i](X[j])\n",
    "        L[0,j] = L_fns[0](p_keys['has_cars'][i])\n",
    "        L[1,j] = L_fns[1](p_keys['has_road'][i])\n",
    "        L[2,j] = L_fns[2](p_keys['has_human'][i], p_keys['has_bike'][i], p_keys['bike_human_distance'][i])\n",
    "        #L[0,j] = L_fns[0](p_keys['has_human'][i], p_keys['has_road'][i])\n",
    "#         L[1,j] = L_fns[1](p_keys['has_human'][i], p_keys['has_cars'][i])\n",
    "#         L[2,j] = L_fns[2](p_keys['has_human'][i], p_keys['has_bike'][i], p_keys['bike_human_distance'][i])\n",
    "#         L[3,j] = L_fns[3](p_keys['has_human'][i], p_keys['has_bike'][i], p_keys['bike_human_size'][i])\n",
    "#         L[4,j] = L_fns[4](p_keys['has_human'][i], p_keys['has_bike'][i], p_keys['bike_human_num'][i])\n",
    "       \n",
    "    L_train = sparse.csr_matrix(L.T)\n",
    "    ds = DependencySelector()\n",
    "    deps = ds.select(L.T, threshold=0.05)\n",
    "    gen_model = GenerativeModel()\n",
    "    gen_model.train(L.T, deps=deps, epochs=epochs, decay=0.95, step_size= 0.01/ L.shape[1], reg_param=1e-6)\n",
    "    if weights is not None:\n",
    "        gen_model.weights = weights\n",
    "    train_marginals, likelihood = gen_model.marginals(L_train)\n",
    "    labels = 2 * (train_marginals > 0.5) - 1\n",
    "    gen = np.mean(labels == Y_train)\n",
    "    f1_gen = f1_score(Y_train, labels)\n",
    "    if weights is None:\n",
    "        return (gen,f1_gen,labels), gen_model.weights, -likelihood \n",
    "    else:\n",
    "        return -likelihood \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.57765597  4.63131153  1.30423208  1.55270378  1.05851542  9.65078869\n",
      "   0.2949134   1.59573973  0.03772962  0.13680092]]\n"
     ]
    }
   ],
   "source": [
    "#L_fns = [LF_street, LF_vehicles, LF_distance, LF_size, LF_number]\n",
    "L_fns = [LF_has_cars, LF_has_cars, LF_distance]\n",
    "ind = [2]\n",
    "lower = 0\n",
    "upper = 50 \n",
    "sim_n = 10 \n",
    "tmp = np.random.uniform(lower, upper, (len(ind),sim_n))\n",
    "acc = [[0,0] for _ in range(sim_n)]\n",
    "acc_baseline = [[0,0] for _ in range(sim_n)]\n",
    "f1 = [[0,0] for _ in range(sim_n)]\n",
    "f1_baseline = [[0,0] for _ in range(sim_n)]\n",
    "one_d = range(100)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.65343915343915349, 0.67167919799498743)\n",
      "(0.64814814814814814, 0.65984654731457804)\n",
      "(0.64814814814814814, 0.65454545454545454)\n",
      "(0.64814814814814814, 0.65454545454545454)\n",
      "(0.64814814814814814, 0.65454545454545454)\n",
      "(0.65079365079365081, 0.66999999999999993)\n",
      "(0.64550264550264547, 0.64921465968586389)\n",
      "(0.64814814814814814, 0.65454545454545454)\n",
      "(0.64550264550264547, 0.64921465968586389)\n",
      "(0.64550264550264547, 0.64921465968586389)\n",
      "0.648148148148 0.656735154255\n"
     ]
    }
   ],
   "source": [
    "# baseline \n",
    "for i in range(10):\n",
    "    tmp_alpha = tmp[:,i]\n",
    "    ans, _, _ = f(tmp_alpha, L_fns=L_fns, ind=ind, epochs=1000)\n",
    "    acc_baseline[i][0], f1_baseline[i][0] = ans[0:2]\n",
    "    print(ans[0:2])\n",
    "    labels = ans[2]\n",
    "    acc_baseline[i][1], f1_baseline[i][1] = metric(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-626.191237369\n",
      "-686.136262116 -652.269011658\n",
      "[ 172.]\n",
      "(0.64814814814814814, 0.65454545454545454)\n",
      "-695.641541392\n",
      "-695.677725937 -658.479324787\n",
      "[ 163.]\n",
      "(0.67989417989417988, 0.71794871794871795)\n",
      "-695.763483625\n",
      "-695.763483625 -658.522406967\n",
      "[ 163.]\n",
      "(0.67724867724867721, 0.71495327102803741)\n",
      "-695.763483625\n",
      "-695.763483625 -658.522406967\n",
      "[ 163.]\n",
      "(0.67724867724867721, 0.71495327102803741)\n",
      "-695.763483625\n",
      "-695.763483625 -658.522406967\n",
      "[ 163.]\n",
      "(0.67724867724867721, 0.71495327102803741)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = [1]\n",
    "#alpha = [20,5000]\n",
    "init = np.zeros((2,1))\n",
    "init[:,0] = [1,10]\n",
    "# init[:,1] = [1, 10, 100]\n",
    "\n",
    "iters = 5\n",
    "for i in range(iters):\n",
    "    ans, weights, fvalue = f(alpha, L_fns=L_fns, ind=ind, epochs=200)\n",
    "    print(fvalue)\n",
    "    f_new = partial(f, L_fns=L_fns, ind=ind, epochs=0, weights=weights)\n",
    "    alpha = minimize(f_new, alpha, options={'initial_simplex':init}, method='Nelder-Mead').x\n",
    "    print(f_new(alpha=alpha), f_new(alpha=[20]))\n",
    "    print(alpha)\n",
    "    print(ans[0:2]) \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
